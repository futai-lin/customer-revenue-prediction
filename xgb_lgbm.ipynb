{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data visualization \n",
    "import matplotlib.pyplot as plt\n",
    "# json\n",
    "import json\n",
    "# sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# lgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# datatime\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(csv_path, nrows=None):\n",
    "    '''\n",
    "    load csv file and convert json columns to normal columns\n",
    "    '''\n",
    "    json_columns = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    df = pd.read_csv(csv_path,\n",
    "                     converters={column: json.loads for column in json_columns},\n",
    "                     dtype={'fullVisitorId': 'str'},\n",
    "                     nrows=nrows)\n",
    "    \n",
    "    for column in json_columns:\n",
    "        column_df = pd.io.json.json_normalize(list(df[column].values))\n",
    "        column_df.columns = [f'{column}.{sub_column}' for sub_column in column_df.columns]\n",
    "        df = df.drop(column, axis=1).join(column_df)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and transform data\n",
    "train_df = load_df('train.csv')\n",
    "test_df = load_df('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgb(X_train, y_train, X_dev, y_dev, X_test):\n",
    "    '''\n",
    "    wrap train, dev and test dataset in LGB\n",
    "    '''\n",
    "    params = {'learning_rate': 0.03,\n",
    "            'objective':'regression',\n",
    "            'metric':'rmse',\n",
    "            'num_leaves': 31,\n",
    "            'verbose': 1,\n",
    "            \"subsample\": 0.99,\n",
    "            \"colsample_bytree\": 0.99,\n",
    "            \"random_state\":42,\n",
    "            'max_depth': 15,\n",
    "            'lambda_l2': 0.02085548700474218,\n",
    "            'lambda_l1': 0.004107624022751344,\n",
    "            'bagging_fraction': 0.7934712636944741,\n",
    "            'feature_fraction': 0.686612409641711,\n",
    "            'min_child_samples': 21}\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "    lgb_dev = lgb.Dataset(X_dev, label=y_dev)\n",
    "    model = lgb.train(params, lgb_train, valid_sets=[lgb_dev], early_stopping_rounds=100, verbose_eval=100)\n",
    "    pred_y_test = model.predict(X_test, num_iteration=model.best_iteration) \n",
    "    pred_y_dev = model.predict(X_dev, num_iteration=model.best_iteration)\n",
    "    return model, pred_y_dev, pred_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "def get_oof(lgb_model, train_df, test_df, select_features):\n",
    "    oof_pred = np.zeros(train_df.shape[0])\n",
    "    sub_pred = np.zeros(test_df.shape[0])\n",
    "    fold_ids = get_fold(train_df)\n",
    "    \n",
    "    for i, (train_idx, dev_idx) in enumerate(fold_ids):\n",
    "        print('processing {} fold: '.format(i))\n",
    "\n",
    "        train_id = train_df['fullVisitorId'].iloc[train_idx].values\n",
    "        train_X = train_df[select_features].iloc[train_idx]\n",
    "        train_y = train_df['totals.transactionRevenue'].iloc[train_idx].values\n",
    "        train_y = np.log1p(train_y)\n",
    "\n",
    "        dev_id = train_df['fullVisitorId'].iloc[dev_idx].values\n",
    "        dev_X = train_df[select_features].iloc[dev_idx]\n",
    "        dev_y = train_df['totals.transactionRevenue'].iloc[dev_idx].values  \n",
    "        dev_y = np.log1p(dev_y)\n",
    "\n",
    "        model, pred_dev, pred_test = run_lgb(train_X, train_y, dev_X, dev_y, test_X)\n",
    "        pred_dev[pred_dev < 0] = 0\n",
    "        pred_test[pred_test < 0] = 0\n",
    "\n",
    "        oof_pred[dev_idx] = np.expm1(pred_dev)\n",
    "        sub_pred += np.expm1(pred_test) / len(fold_ids)\n",
    "        \n",
    "        # n fold rmse \n",
    "        pred_dev_df = pd.DataFrame({'fullVisitorId': dev_id})\n",
    "        pred_dev_df['transactionRevenue'] = dev_y\n",
    "        pred_dev_df['predictedRevenue'] = np.expm1(pred_dev)\n",
    "        pred_dev_df = pred_dev_df.groupby('fullVisitorId')[['transactionRevenue', 'predictedRevenue']].sum()\n",
    "        rmse_score = rmse(np.log1p(pred_dev_df['transactionRevenue'].values), np.log1p(pred_dev_df['predictedRevenue'].values))\n",
    "        print('{} fold rmse:'.format(rmse_score))\n",
    "    return oof_pred, sub_pred\n",
    "        \n",
    "    def get_fold(train_df, kfold = 5):   \n",
    "        '''\n",
    "        kfold based on unique fullVisitorId\n",
    "        '''\n",
    "        unique_vis = np.array(sorted(train_df['fullVisitorId'].unique()))\n",
    "        folds = GroupKFold(n_splits=kfold)\n",
    "        fold_ids = []\n",
    "        ids = np.arange(df.shape[0])\n",
    "        for train_vis, dev_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n",
    "            fold_ids.append([\n",
    "                ids[df['fullVisitorId'].isin(unique_vis[train_vis])],\n",
    "                ids[df['fullVisitorId'].isin(unique_vis[dev_vis])]\n",
    "            ])\n",
    "        return fold_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the metrics: rmse(root mean square error)\n",
    "def rmse(y, y0):\n",
    "    assert len(y) == len(y0)\n",
    "    return np.sqrt(np.mean(np.power((y - y0), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "def preprocess(train_df, test_df):\n",
    "    num_columns = ['totals.bounces', 'totals.hits', 'totals.newVisits', 'totals.pageviews', 'visitNumber', 'visitStartTime']\n",
    "    cat_columns = ['channelGrouping',\n",
    "                   'device.browser',\n",
    "                   'device.deviceCategory',\n",
    "                   'device.operatingSystem',\n",
    "                   'geoNetwork.city',\n",
    "                   'geoNetwork.continent',\n",
    "                   'geoNetwork.country',\n",
    "                   'geoNetwork.metro',\n",
    "                   'geoNetwork.networkDomain',\n",
    "                   'geoNetwork.region',\n",
    "                   'geoNetwork.subContinent',\n",
    "                   'trafficSource.adContent',\n",
    "                   'trafficSource.adwordsClickInfo.adNetworkType',\n",
    "                   'trafficSource.adwordsClickInfo.gclId',\n",
    "                   'trafficSource.adwordsClickInfo.isVideoAd',\n",
    "                   'trafficSource.adwordsClickInfo.page',\n",
    "                   'trafficSource.adwordsClickInfo.slot',\n",
    "                   'trafficSource.campaign',\n",
    "                   'trafficSource.isTrueDirect',\n",
    "                   'trafficSource.keyword',\n",
    "                   'trafficSource.medium',\n",
    "                   'trafficSource.referralPath',\n",
    "                   'trafficSource.source']\n",
    "    \n",
    "    for column in cat_columns:\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train_df[column].values.astype('str')) + list(test_df[column].values.astype('str')))\n",
    "        train_df[column] = lbl.transform(list(train_df[column].values.astype('str')))\n",
    "        test_df[column] = lbl.transform(list(test_df[column].values.astype('str')))\n",
    "    \n",
    "    train_df[num_columns] = train_df[num_columns].astype(float)\n",
    "    test_df[num_columns] = test_df[num_columns].astype(float)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d69bfbb5a5c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-cab9434a887e>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(train_df, test_df)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mlbl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'str'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'str'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlbl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'str'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlbl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'str'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_columns\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersect1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid axis kwarg specified for unique'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[0mFind\u001b[0m \u001b[0mthe\u001b[0m \u001b[0munique\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignoring\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \"\"\"\n\u001b[1;32m--> 261\u001b[1;33m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[0moptional_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_df, test_df = preprocess(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
